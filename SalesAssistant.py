# sales_assistant.py
"""
ä¸Šä¸‹æ–‡æ„ŸçŸ¥æ™ºèƒ½é”€å”®åŠ©æ‰‹ (Context-Aware Sales Assistant)
ä½¿ç”¨ LangChain + LLM + RAG æ„å»º
"""

import os
from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime

from langchain_community.chat_models import ChatZhipuAI
# LangChain ç›¸å…³ç»„ä»¶
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import ZhipuAIEmbeddings
# from langchain_community.llms import Ollama  # ä½¿ç”¨æœ¬åœ° Ollama æ¨¡å‹ï¼Œä¹Ÿå¯æ›¿æ¢ä¸ºå…¶ä»– LLM
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import TextLoader, DirectoryLoader

import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class CustomerContext:
    """å®¢æˆ·ä¸Šä¸‹æ–‡ä¿¡æ¯"""
    name: str
    company: str
    industry: str
    position: str
    interests: List[str]
    pain_points: List[str]
    previous_interactions: List[str]
    budget_range: str
    decision_timeline: str


@dataclass
class SalesContext:
    """é”€å”®åœºæ™¯ä¸Šä¸‹æ–‡"""
    meeting_type: str  # "initial", "follow_up", "demo", "negotiation"
    current_stage: str
    goals: List[str]
    constraints: List[str]
    customer_emotion: str  # "interested", "skeptical", "urgent", "neutral"


class KnowledgeBase:
    """äº§å“çŸ¥è¯†åº“ç®¡ç†"""
    
    def __init__(self, data_dir: str = "data/knowledge_base"):
        self.data_dir = data_dir
        self.embeddings = ZhipuAIEmbeddings(model="embedding-3",
                                            api_key="0f4ae0b90dff44389836ecf634297560.c1eOL2jdMckW1bfO")
        self.vectorstore = None
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len
        )
    
    def load_documents(self):
        """åŠ è½½çŸ¥è¯†åº“æ–‡æ¡£"""
        # documents = TextLoader("data/knowledge_base/835033325.txt", autodetect_encoding=True).load()
        # print(documents)
        # logger.info(f"åŠ è½½äº† {len(documents)} ä¸ªæ–‡æ¡£")
        # return documents
        try:
            loader = DirectoryLoader(
                self.data_dir,
                glob="**/*.txt",
                loader_cls=TextLoader,
                loader_kwargs={'autodetect_encoding': True}
            )
            documents = loader.load()
            # documents = TextLoader("data/knowledge_base/835033325.txt").load()
            # print(documents)
            logger.info(f"åŠ è½½äº† {len(documents)} ä¸ªæ–‡æ¡£")
            return documents
        except Exception as e:
            logger.error(f"åŠ è½½æ–‡æ¡£å¤±è´¥: {e}")
            return []
    
    def create_vectorstore(self):
        """åˆ›å»ºå‘é‡æ•°æ®åº“"""
        documents = self.load_documents()
        if not documents:
            logger.warning("æ²¡æœ‰æ‰¾åˆ°æ–‡æ¡£ï¼Œåˆ›å»ºç©ºçš„çŸ¥è¯†åº“")
            return
        
        texts = self.text_splitter.split_documents(documents)
        logger.info(f"åˆ†å‰²æˆ {len(texts)} ä¸ªæ–‡æœ¬å—")
        
        # åˆ›å»ºå‘é‡æ•°æ®åº“
        self.vectorstore = Chroma.from_documents(
            texts,
            self.embeddings,
            persist_directory="./chroma_db"
        )
        logger.info("å‘é‡æ•°æ®åº“åˆ›å»ºå®Œæˆ")
    
    def get_retriever(self):
        
        if self.vectorstore is None:
            self.create_vectorstore()
        
        if self.vectorstore is None:
            raise ValueError("å‘é‡æ•°æ®åº“æœªåˆ›å»ºï¼Œè¯·æ£€æŸ¥çŸ¥è¯†åº“æ–‡ä»¶æ˜¯å¦åŠ è½½æˆåŠŸ")
        
        return self.vectorstore.as_retriever(search_kwargs={"k": 3})


class SalesAssistant:
    """æ™ºèƒ½é”€å”®åŠ©æ‰‹ä¸»ç±»"""
    
    def __init__(self):
        self.knowledge_base = KnowledgeBase()
        self.llm = ChatZhipuAI(
            temperature=0.95,
            model="glm-4",
            api_key="0f4ae0b90dff44389836ecf634297560.c1eOL2jdMckW1bfO",
        )
        self.retriever = self.knowledge_base.get_retriever()
        
        # åˆ›å»º RAG é“¾
        self.rag_chain = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=self.retriever,
            return_source_documents=True
        )
        
        # è‡ªå®šä¹‰æç¤ºæ¨¡æ¿
        self.prompt_template = """
        ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„é”€å”®é¡¾é—®ï¼Œæ­£åœ¨å¸®åŠ©é”€å”®ä»£è¡¨ä¸å®¢æˆ· {customer_name} è¿›è¡Œæ²Ÿé€šã€‚
        å®¢æˆ·å…¬å¸ï¼š{company}
        è¡Œä¸šï¼š{industry}
        èŒä½ï¼š{position}
        å…³æ³¨ç‚¹ï¼š{interests}
        ç—›ç‚¹ï¼š{pain_points}
        é¢„ç®—ï¼š{budget_range}
        å†³ç­–æ—¶é—´ï¼š{decision_timeline}

        å½“å‰é”€å”®åœºæ™¯ï¼š
        - ä¼šè®®ç±»å‹ï¼š{meeting_type}
        - é”€å”®é˜¶æ®µï¼š{current_stage}
        - ç›®æ ‡ï¼š{goals_str}
        - é™åˆ¶ï¼š{constraints_str}
        - å®¢æˆ·æƒ…ç»ªï¼š{customer_emotion}

        ç›¸å…³çŸ¥è¯†åº“ä¿¡æ¯ï¼š
        {context}

        è¯·æ ¹æ®ä»¥ä¸Šä¿¡æ¯ï¼Œæä¾›ä¸“ä¸šçš„é”€å”®å»ºè®®ï¼š
        1. é’ˆå¯¹å®¢æˆ·ç—›ç‚¹çš„è§£å†³æ–¹æ¡ˆå»ºè®®
        2. äº§å“ä¼˜åŠ¿çš„é’ˆå¯¹æ€§ä»‹ç»
        3. åº”å¯¹å®¢æˆ·å¯èƒ½æå‡ºçš„é—®é¢˜
        4. æ¨è¿›é”€å”®è¿›ç¨‹çš„ç­–ç•¥
        5. å»ºè®®çš„æ²Ÿé€šè¯æœ¯

        è¯·ç”¨ä¸“ä¸šã€ç®€æ´ã€æœ‰è¯´æœåŠ›çš„è¯­è¨€å›ç­”ã€‚
        """
        
        self.prompt = PromptTemplate(
            template=self.prompt_template,
            input_variables=[
                "customer_name", "company", "industry", "position",
                "interests", "pain_points", "budget_range", "decision_timeline",
                "meeting_type", "current_stage", "goals_str", "constraints_str",
                "customer_emotion", "context"
            ]
        )
    
    def _format_context(self, source_documents) -> str:
        """æ ¼å¼åŒ–æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡"""
        context = ""
        for i, doc in enumerate(source_documents):
            context += f"ã€å‚è€ƒä¿¡æ¯ {i + 1}ã€‘\n{doc.page_content}\næ¥æº: {doc.metadata.get('source', 'æœªçŸ¥')}\n\n"
        return context
    
    def _prepare_context_input(self, customer_context: CustomerContext,
                               sales_context: SalesContext) -> Dict:
        """å‡†å¤‡ä¸Šä¸‹æ–‡è¾“å…¥"""
        return {
            "customer_name": customer_context.name,
            "company": customer_context.company,
            "industry": customer_context.industry,
            "position": customer_context.position,
            "interests": ", ".join(customer_context.interests),
            "pain_points": ", ".join(customer_context.pain_points),
            "budget_range": customer_context.budget_range,
            "decision_timeline": customer_context.decision_timeline,
            "meeting_type": sales_context.meeting_type,
            "current_stage": sales_context.current_stage,
            "goals_str": ", ".join(sales_context.goals),
            "constraints_str": ", ".join(sales_context.constraints),
            "customer_emotion": sales_context.customer_emotion
        }
    
    def get_sales_advice(self,
                         customer_context: CustomerContext,
                         sales_context: SalesContext) -> Dict:
        """
        è·å–é”€å”®å»ºè®®

        Args:
            customer_context: å®¢æˆ·ä¸Šä¸‹æ–‡
            sales_context: é”€å”®åœºæ™¯ä¸Šä¸‹æ–‡

        Returns:
            åŒ…å«å»ºè®®å’Œæ¥æºçš„å­—å…¸
        """
        try:
            # æ£€ç´¢ç›¸å…³çŸ¥è¯†
            query = f"è§£å†³{customer_context.industry}è¡Œä¸šå®¢æˆ·å…³äº{', '.join(customer_context.pain_points)}çš„é—®é¢˜"
            retrieval_result = self.retriever.invoke(query)
            
            # å‡†å¤‡è¾“å…¥
            context_input = self._prepare_context_input(customer_context, sales_context)
            context_input["context"] = self._format_context(retrieval_result)
            
            # åˆ›å»ºæœ€ç»ˆæç¤º
            final_prompt = self.prompt.format(**context_input)
            
            # è°ƒç”¨ LLM
            response = self.llm.invoke(final_prompt)
            
            return {
                "advice": response,
                "source_documents": [
                    {
                        "content": doc.page_content,
                        "source": doc.metadata.get("source", "æœªçŸ¥")
                    }
                    for doc in retrieval_result
                ],
                "timestamp": datetime.now().isoformat(),
                "success": True
            }
        
        except Exception as e:
            logger.error(f"è·å–é”€å”®å»ºè®®å¤±è´¥: {e}")
            return {
                "advice": f"æŠ±æ­‰ï¼Œè·å–é”€å”®å»ºè®®æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}",
                "source_documents": [],
                "timestamp": datetime.now().isoformat(),
                "success": False
            }
    
    def analyze_customer_sentiment(self, conversation_text: str) -> Dict:
        """
        åˆ†æå®¢æˆ·æƒ…ç»ªï¼ˆç®€å•å®ç°ï¼‰
        """
        prompt = f"""
        è¯·åˆ†æä»¥ä¸‹å®¢æˆ·å¯¹è¯çš„æƒ…ç»ªçŠ¶æ€ï¼Œä»ä»¥ä¸‹ç±»åˆ«ä¸­é€‰æ‹©æœ€åˆé€‚çš„ï¼š
        - å…´å¥‹ (Excited)
        - æ„Ÿå…´è¶£ (Interested)
        - æ€€ç–‘ (Skeptical)
        - çŠ¹è±« (Hesitant)
        - ç´§è¿« (Urgent)
        - ä¸­ç«‹ (Neutral)
        - ä¸æ»¡ (Dissatisfied)

        å¯¹è¯å†…å®¹ï¼š
        {conversation_text}

        è¯·åªè¿”å›æƒ…ç»ªç±»åˆ«ï¼Œå¹¶ç®€è¦è¯´æ˜ç†ç”±ã€‚
        """
        
        try:
            response = self.llm.invoke(prompt)
            return {"sentiment": response.strip(), "success": True}
        except Exception as e:
            return {"sentiment": "åˆ†æå¤±è´¥", "error": str(e), "success": False}


# ç¤ºä¾‹ä½¿ç”¨å’Œæµ‹è¯•
def create_sample_data():
    """åˆ›å»ºç¤ºä¾‹æ•°æ®"""
    os.makedirs("data/knowledge_base", exist_ok=True)
    
    # åˆ›å»ºäº§å“çŸ¥è¯†åº“ç¤ºä¾‹
    knowledge_content = """
    äº§å“åç§°ï¼šæ™ºèƒ½CRMç³»ç»Ÿ
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. å®¢æˆ·å…³ç³»ç®¡ç†ï¼šå…¨é¢è·Ÿè¸ªå®¢æˆ·ä¿¡æ¯å’Œäº’åŠ¨å†å²
    2. é”€å”®ç®¡é“è‡ªåŠ¨åŒ–ï¼šè‡ªåŠ¨æ¨è¿›é”€å”®æµç¨‹ï¼Œå‡å°‘æ‰‹åŠ¨æ“ä½œ
    3. æ•°æ®åˆ†æä»ªè¡¨æ¿ï¼šå®æ—¶é”€å”®æ•°æ®å¯è§†åŒ–
    4. æ™ºèƒ½æé†’ï¼šå…³é”®èŠ‚ç‚¹è‡ªåŠ¨æé†’
    5. ç§»åŠ¨ç«¯æ”¯æŒï¼šéšæ—¶éšåœ°è®¿é—®å®¢æˆ·ä¿¡æ¯

    è¡Œä¸šè§£å†³æ–¹æ¡ˆï¼š
    - åˆ¶é€ ä¸šï¼šè®¾å¤‡ç»´æŠ¤æé†’ï¼Œä¾›åº”é“¾ååŒ
    - é›¶å”®ä¸šï¼šå®¢æˆ·è¡Œä¸ºåˆ†æï¼Œä¸ªæ€§åŒ–æ¨è
    - é‡‘èä¸šï¼šåˆè§„æ€§ç®¡ç†ï¼Œé£é™©è¯„ä¼°
    - æ•™è‚²è¡Œä¸šï¼šå­¦å‘˜ç®¡ç†ï¼Œè¯¾ç¨‹æ¨è

    å®šä»·æ–¹æ¡ˆï¼š
    åŸºç¡€ç‰ˆï¼š$99/ç”¨æˆ·/æœˆï¼ŒåŒ…å«æ ¸å¿ƒCRMåŠŸèƒ½
    ä¸“ä¸šç‰ˆï¼š$199/ç”¨æˆ·/æœˆï¼Œå¢åŠ è‡ªåŠ¨åŒ–å’Œåˆ†æåŠŸèƒ½
    ä¼ä¸šç‰ˆï¼šå®šåˆ¶æŠ¥ä»·ï¼ŒåŒ…å«APIé›†æˆå’Œé«˜çº§å®‰å…¨

    å¸¸è§å®¢æˆ·ç—›ç‚¹è§£å†³æ–¹æ¡ˆï¼š
    - å®¢æˆ·è·Ÿè¿›ä¸åŠæ—¶ï¼šé€šè¿‡è‡ªåŠ¨åŒ–æé†’è§£å†³
    - é”€å”®é¢„æµ‹ä¸å‡†ï¼šé€šè¿‡AIé¢„æµ‹æ¨¡å‹è§£å†³
    - æ•°æ®åˆ†æ•£ï¼šé€šè¿‡ç»Ÿä¸€å¹³å°æ•´åˆ
    - å›¢é˜Ÿåä½œå›°éš¾ï¼šé€šè¿‡å…±äº«ä»ªè¡¨æ¿è§£å†³
    """
    
    with open("data/knowledge_base/product_info.txt", "w", encoding="utf-8") as f:
        f.write(knowledge_content)


def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºä½¿ç”¨"""
    print("ğŸš€ å¯åŠ¨ä¸Šä¸‹æ–‡æ„ŸçŸ¥æ™ºèƒ½é”€å”®åŠ©æ‰‹...")
    
    # åˆ›å»ºç¤ºä¾‹æ•°æ®
    create_sample_data()
    
    # åˆå§‹åŒ–åŠ©æ‰‹
    assistant = SalesAssistant()
    
    # åˆ›å»ºå®¢æˆ·ä¸Šä¸‹æ–‡
    customer = CustomerContext(
        name="å¼ ä¼Ÿ",
        company="åˆ›æ–°ç§‘æŠ€æœ‰é™å…¬å¸",
        industry="åˆ¶é€ ä¸š",
        position="é”€å”®æ€»ç›‘",
        interests=["é”€å”®è‡ªåŠ¨åŒ–", "æ•°æ®åˆ†æ", "å›¢é˜Ÿåä½œ"],
        pain_points=["å®¢æˆ·è·Ÿè¿›ä¸åŠæ—¶", "é”€å”®é¢„æµ‹ä¸å‡†"],
        previous_interactions=[
            "2025-10-25: åˆæ­¥ç”µè¯æ²Ÿé€šï¼Œè¡¨è¾¾äº†å¯¹è‡ªåŠ¨åŒ–åŠŸèƒ½çš„å…´è¶£",
            "2025-10-28: å‘é€äº†äº§å“èµ„æ–™å’Œæ¡ˆä¾‹ç ”ç©¶"
        ],
        budget_range="ä¸­ç­‰",
        decision_timeline="1-2ä¸ªæœˆ"
    )
    
    # åˆ›å»ºé”€å”®åœºæ™¯ä¸Šä¸‹æ–‡
    sales_context = SalesContext(
        meeting_type="follow_up",
        current_stage="éœ€æ±‚ç¡®è®¤",
        goals=["ç¡®è®¤å…·ä½“éœ€æ±‚", "å®‰æ’äº§å“æ¼”ç¤º", "äº†è§£é¢„ç®—ç»†èŠ‚"],
        constraints=["å®¢æˆ·æ—¶é—´ç´§å¼ ", "éœ€è¦é«˜å±‚æ‰¹å‡†"],
        customer_emotion="interested"
    )
    
    print("\nğŸ‘¤ å®¢æˆ·ä¿¡æ¯:")
    print(f"  åç§°: {customer.name}")
    print(f"  å…¬å¸: {customer.company}")
    print(f"  è¡Œä¸š: {customer.industry}")
    print(f"  ç—›ç‚¹: {', '.join(customer.pain_points)}")
    
    print(f"\nğŸ¯ é”€å”®åœºæ™¯:")
    print(f"  ä¼šè®®ç±»å‹: {sales_context.meeting_type}")
    print(f"  å½“å‰é˜¶æ®µ: {sales_context.current_stage}")
    print(f"  ç›®æ ‡: {', '.join(sales_context.goals)}")
    
    print("\nğŸ’¡ æ­£åœ¨è·å–é”€å”®å»ºè®®...")
    
    # è·å–é”€å”®å»ºè®®
    result = assistant.get_sales_advice(customer, sales_context)
    
    if result["success"]:
        print("\nâœ… æ™ºèƒ½é”€å”®å»ºè®®:")
        print(result["advice"])
        
        print(f"\nğŸ“š ä¿¡æ¯æ¥æº:")
        for i, source in enumerate(result["source_documents"]):
            print(f"  [{i + 1}] {source['source']}")
    else:
        print(f"âŒ é”™è¯¯: {result['advice']}")
    
    # æƒ…ç»ªåˆ†æç¤ºä¾‹
    conversation = """
    å®¢æˆ·ï¼šæˆ‘å¯¹ä½ ä»¬çš„è‡ªåŠ¨åŒ–åŠŸèƒ½å¾ˆæ„Ÿå…´è¶£ï¼Œç‰¹åˆ«æ˜¯å®¢æˆ·è·Ÿè¿›æé†’ã€‚
    ä½†æ˜¯ä»·æ ¼æ–¹é¢è¿˜éœ€è¦å’Œè´¢åŠ¡éƒ¨é—¨è®¨è®ºã€‚
    æˆ‘ä»¬ç¡®å®éœ€è¦è§£å†³è·Ÿè¿›ä¸åŠæ—¶çš„é—®é¢˜ï¼Œè¿™å½±å“äº†æˆ‘ä»¬çš„æˆäº¤ç‡ã€‚
    æˆ‘å¾ˆé«˜å…´ä½ ä»¬èƒ½æä¾›è¿™æ–¹é¢çš„è§£å†³æ–¹æ¡ˆã€‚
    """
    
    sentiment = assistant.analyze_customer_sentiment(conversation)
    print(f"\nğŸ˜Š å®¢æˆ·æƒ…ç»ªåˆ†æ: {sentiment.get('sentiment', 'æœªçŸ¥')}")


if __name__ == "__main__":
    main()
